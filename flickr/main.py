"""
Flickr Album Downloader
========================
Pobiera zdjÄ™cia z albumu Flickr w NAJWYÅ»SZEJ DOSTÄ˜PNEJ ROZDZIELCZOÅšCI.

Program automatycznie wykrywa i pobiera zdjÄ™cia w najlepszej jakoÅ›ci:
- Original (oryginaÅ‚, jeÅ›li dostÄ™pny)
- X-Large 5K, 4K, 3K
- Large 2048, 1600, 1024
- Medium (jako fallback)

Zapisuje:
- ZdjÄ™cia w folderze z nazwami zgodnie z tytuÅ‚em w albumie
- Plik photo_urls.txt z listÄ…: nazwa_pliku, URL, tytuÅ‚, rozdzielczoÅ›Ä‡
- Plik failed_downloads.txt z listÄ… nieudanych pobraÅ„

KaÅ¼de zdjÄ™cie jest pobierane indywidualnie z jego strony /sizes/, 
aby uzyskaÄ‡ najlepszÄ… moÅ¼liwÄ… jakoÅ›Ä‡.

Funkcje inteligentnego wznowienia:
âœ“ Automatycznie pomija juÅ¼ pobrane pliki
âœ“ Wznawia pobieranie nieudanych plikÃ³w przy ponownym uruchomieniu
âœ“ Wykrywa uszkodzone pliki (< 1KB) i pobiera je ponownie
âœ“ Åšledzi postÄ™p w plikach tekstowych
âœ“ ObsÅ‚uga rate limit (HTTP 429) - automatyczna pauza 30 minut

Uruchom program ponownie, aby kontynuowaÄ‡ przerwane pobieranie!
"""

import os
import time
import requests
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
import re
import threading
from queue import Queue
from tqdm import tqdm

class FlickrAlbumDownloader:
    def __init__(self, album_url, download_folder="flickr_photos"):
        self.album_url = album_url.rstrip('/')
        self.download_folder = download_folder
        self.driver = None
        self.photo_urls = set()  # UÅ¼ywamy set aby uniknÄ…Ä‡ duplikatÃ³w
        self.urls_file = os.path.join(download_folder, "photo_urls.txt")
        self.failed_file = os.path.join(download_folder, "failed_downloads.txt")
        self.download_queue = Queue()
        self.download_stats = {"successful": 0, "failed": 0, "skipped": 0, "resumed": 0, "skipped_scan": 0, "from_cache": 0}
        self.download_lock = threading.Lock()
        self.rate_limit_event = threading.Event()  # SygnaÅ‚ pauzy przy rate limit
        self.rate_limit_event.set()  # DomyÅ›lnie wÅ‚Ä…czony (nie pauzowany)
        self.downloaded_files = set()  # JuÅ¼ pobrane pliki
        self.failed_files = set()  # Pliki, ktÃ³re siÄ™ nie udaÅ‚y
        self.known_urls = {}  # Mapowanie: filename -> (url, title, size)
        self.global_index = 0  # Globalny licznik zdjÄ™Ä‡ dla kolejki
        self.total_photos = 0  # CaÅ‚kowita liczba zdjÄ™Ä‡ w albumie
        self.download_pbar = None  # Progress bar dla pobierania
        
        # UtwÃ³rz folder na zdjÄ™cia
        if not os.path.exists(download_folder):
            os.makedirs(download_folder)
        
        # Wczytaj listÄ™ juÅ¼ pobranych plikÃ³w i znanych URL-i
        self._load_known_urls()
        self._load_downloaded_files()
        self._load_failed_files()
    
    def _load_known_urls(self):
        """Wczytaj znane URL-e z pliku photo_urls.txt"""
        if os.path.exists(self.urls_file):
            with open(self.urls_file, 'r', encoding='utf-8') as f:
                for line in f:
                    parts = line.strip().split('\t')
                    if len(parts) >= 2:
                        filename = parts[0]
                        url = parts[1]
                        title = parts[2] if len(parts) > 2 else ""
                        size = parts[3] if len(parts) > 3 else "unknown"
                        self.known_urls[filename] = (url, title, size)
                        self.photo_urls.add(url)  # Dodaj do zestawu URL-i
            
            if self.known_urls:
                print(f"ğŸ“‹ Wczytano {len(self.known_urls)} znanych URL-i z pliku")
    
    def _load_downloaded_files(self):
        """Wczytaj listÄ™ juÅ¼ pobranych plikÃ³w z folderu"""
        if os.path.exists(self.download_folder):
            for filename in os.listdir(self.download_folder):
                if filename.lower().endswith('.jpg'):
                    # SprawdÅº czy plik nie jest pusty lub zbyt maÅ‚y (< 1KB = prawdopodobnie bÅ‚Ä™dny)
                    filepath = os.path.join(self.download_folder, filename)
                    if os.path.getsize(filepath) > 1024:
                        self.downloaded_files.add(filename)
        
        if self.downloaded_files:
            print(f"âœ“ Znaleziono {len(self.downloaded_files)} juÅ¼ pobranych plikÃ³w")
    
    def _load_failed_files(self):
        """Wczytaj listÄ™ plikÃ³w, ktÃ³re wczeÅ›niej siÄ™ nie udaÅ‚y"""
        if os.path.exists(self.failed_file):
            with open(self.failed_file, 'r', encoding='utf-8') as f:
                for line in f:
                    # Format: filename\turl\terror
                    parts = line.strip().split('\t')
                    if parts:
                        self.failed_files.add(parts[0])
            
            if self.failed_files:
                print(f"âš  Znaleziono {len(self.failed_files)} nieudanych pobraÅ„ do ponowienia")
    
    def _save_failed_download(self, filename, url, error):
        """Zapisz informacjÄ™ o nieudanym pobraniu"""
        with open(self.failed_file, 'a', encoding='utf-8') as f:
            f.write(f"{filename}\t{url}\t{error}\n")
    
    def _is_already_downloaded(self, filename):
        """SprawdÅº czy plik jest juÅ¼ pobrany (i nie jest uszkodzony)"""
        if filename in self.downloaded_files:
            return True
        
        # SprawdÅº fizycznie w folderze
        filepath = os.path.join(self.download_folder, filename)
        if os.path.exists(filepath) and os.path.getsize(filepath) > 1024:
            self.downloaded_files.add(filename)
            return True
        
        return False
    
    def setup_driver(self):
        """Konfiguracja Selenium WebDriver"""
        chrome_options = Options()
        chrome_options.add_argument('--headless')  # UsuÅ„ tÄ™ liniÄ™ jeÅ›li chcesz widzieÄ‡ przeglÄ…darkÄ™
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-blink-features=AutomationControlled')
        chrome_options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')
        
        self.driver = webdriver.Chrome(options=chrome_options)
        self.driver.maximize_window()
    
    def get_total_photos_count(self):
        """Pobierz caÅ‚kowitÄ… liczbÄ™ zdjÄ™Ä‡ z albumu ze strony"""
        try:
            # Szukaj elementu z liczbÄ… zdjÄ™Ä‡: <span class="stat photo-count">257 photos</span>
            count_element = self.driver.find_element(By.CSS_SELECTOR, ".stat.photo-count")
            text = count_element.text.strip()
            # WyciÄ…gnij liczbÄ™ z tekstu "257 photos"
            match = re.search(r'(\d+)', text)
            if match:
                return int(match.group(1))
        except:
            pass
        
        # Fallback - sprÃ³buj innych selektorÃ³w
        try:
            page_source = self.driver.page_source
            match = re.search(r'(\d+)\s*photos', page_source, re.IGNORECASE)
            if match:
                return int(match.group(1))
        except:
            pass
        
        return 0
    
    def get_total_pages(self):
        """Wykryj caÅ‚kowitÄ… liczbÄ™ stron w albumie"""
        max_page = 1
        
        try:
            # METODA 1: Szukaj linkÃ³w paginacji z rÃ³Å¼nymi selektorami
            selectors = [
                ".pagination-view a[href*='page']",
                "a[href*='/page']",
                ".pagination a[href*='page']",
                "[class*='pagination'] a[href*='page']"
            ]
            
            for selector in selectors:
                pagination_links = self.driver.find_elements(By.CSS_SELECTOR, selector)
                for link in pagination_links:
                    href = link.get_attribute('href')
                    # WyciÄ…gnij numer strony z URL
                    match = re.search(r'/page(\d+)', href)
                    if match:
                        page_num = int(match.group(1))
                        max_page = max(max_page, page_num)
                
                if max_page > 1:
                    break
            
            # METODA 2: Szukaj tekstu typu "1 of 3" lub "Strona 1 z 3"
            if max_page == 1:
                try:
                    page_text = self.driver.find_element(By.CSS_SELECTOR, ".pagination-view").text
                    match = re.search(r'(\d+)\s*(?:of|z)\s*(\d+)', page_text, re.IGNORECASE)
                    if match:
                        max_page = int(match.group(2))
                except:
                    pass
            
            # METODA 3: Szukaj caÅ‚kowitej liczby zdjÄ™Ä‡ w albumie i oblicz strony
            if max_page == 1:
                try:
                    # Flickr zazwyczaj pokazuje liczbÄ™ zdjÄ™Ä‡ np. "257 photos"
                    count_elements = self.driver.find_elements(By.CSS_SELECTOR, "[class*='count'], [class*='total'], .album-info")
                    for el in count_elements:
                        text = el.text
                        match = re.search(r'(\d+)\s*(?:photos|zdjÄ™Ä‡|elementÃ³w|items)', text, re.IGNORECASE)
                        if match:
                            total_photos = int(match.group(1))
                            # Flickr pokazuje ~100 zdjÄ™Ä‡ na stronÄ™
                            max_page = (total_photos + 99) // 100  # ZaokrÄ…glij w gÃ³rÄ™
                            print(f"  ğŸ“Š Wykryto {total_photos} zdjÄ™Ä‡ w albumie")
                            break
                except:
                    pass
            
            # METODA 4: SprawdÅº nagÅ‚Ã³wek strony lub metadane
            if max_page == 1:
                try:
                    # Szukaj w tytule strony lub innych miejscach
                    page_source = self.driver.page_source
                    matches = re.findall(r'(\d+)\s*(?:photos|items|zdjÄ™Ä‡)', page_source, re.IGNORECASE)
                    for m in matches:
                        count = int(m)
                        if count > 100:  # Prawdopodobnie to caÅ‚kowita liczba
                            max_page = (count + 99) // 100
                            print(f"  ğŸ“Š Wykryto ~{count} zdjÄ™Ä‡ (z metadanych)")
                            break
                except:
                    pass
            
            return max_page
            
        except Exception as e:
            print(f"Nie moÅ¼na wykryÄ‡ liczby stron, zakÅ‚adam 1 stronÄ™: {e}")
            return 1
    
    def scroll_to_load_all_on_page(self):
        """PrzewiÅ„ stronÄ™, aby zaÅ‚adowaÄ‡ wszystkie zdjÄ™cia na bieÅ¼Ä…cej stronie"""
        last_height = self.driver.execute_script("return document.body.scrollHeight")
        photos_loaded = 0
        stagnant_count = 0
        
        while stagnant_count < 3:  # JeÅ›li 3 razy z rzÄ™du brak zmian, koÅ„czymy
            # PrzewiÅ„ do koÅ„ca strony
            self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(1.5)
            
            # SprawdÅº ile zdjÄ™Ä‡ jest zaÅ‚adowanych
            current_photos = len(self.driver.find_elements(By.CSS_SELECTOR, "img[src*='staticflickr.com']"))
            if current_photos > photos_loaded:
                photos_loaded = current_photos
                stagnant_count = 0
            else:
                stagnant_count += 1
            
            # SprawdÅº czy osiÄ…gniÄ™to koniec strony
            new_height = self.driver.execute_script("return document.body.scrollHeight")
            if new_height == last_height:
                stagnant_count += 1
            else:
                stagnant_count = 0
            last_height = new_height
        
        return photos_loaded
    
    def get_highest_resolution_url(self, photo_page_url):
        """
        Otwiera stronÄ™ zdjÄ™cia w najwyÅ¼szej rozdzielczoÅ›ci i zwraca bezpoÅ›redni URL
        
        Strategia:
        1. PrÃ³buje otworzyÄ‡ /sizes/5k/ (najwyÅ¼sza rozdzielczoÅ›Ä‡ X-Large 5K)
        2. JeÅ›li nie istnieje, Flickr przekieruje na /sizes/o/ lub najwyÅ¼szÄ… dostÄ™pnÄ…
        3. Pobiera URL obrazka z img src (zawiera prawidÅ‚owy secret dla tego zdjÄ™cia)
        """
        try:
            # Wykryj uÅ¼ytkownika i ID zdjÄ™cia z URL
            match = re.search(r'/photos/([^/]+)/(\d+)', photo_page_url)
            if not match:
                return None, None
            
            username = match.group(1)
            photo_id = match.group(2)
            
            # Lista rozdzielczoÅ›ci do sprawdzenia (od najwyÅ¼szej do najniÅ¼szej)
            # Flickr automatycznie przekieruje na najwyÅ¼szÄ… dostÄ™pnÄ… jeÅ›li Å¼Ä…dana nie istnieje
            size_urls_to_try = [
                f"https://www.flickr.com/photos/{username}/{photo_id}/sizes/5k/",
                f"https://www.flickr.com/photos/{username}/{photo_id}/sizes/4k/",
                f"https://www.flickr.com/photos/{username}/{photo_id}/sizes/o/",
            ]
            
            # OtwÃ³rz stronÄ™ z rozmiarami w nowej karcie
            self.driver.execute_script(f"window.open('{size_urls_to_try[0]}', '_blank');")
            self.driver.switch_to.window(self.driver.window_handles[-1])
            
            time.sleep(1.5)  # Poczekaj na zaÅ‚adowanie i ewentualne przekierowanie
            
            # SprÃ³buj znaleÅºÄ‡ najwyÅ¼szÄ… dostÄ™pnÄ… rozdzielczoÅ›Ä‡
            best_url = None
            best_size_name = None
            
            # PRIORYTET 1: SprawdÅº obrazek na stronie (zawiera secret i jest w najwyÅ¼szej dostÄ™pnej rozdzielczoÅ›ci)
            try:
                img = self.driver.find_element(By.CSS_SELECTOR, "#allsizes-photo img")
                best_url = img.get_attribute('src')
                
                # Wykryj rozmiar z URL (np. _5k.jpg, _4k.jpg, _o.jpg)
                size_match = re.search(r'_([a-z0-9]+)\.jpg$', best_url)
                if size_match:
                    best_size_name = size_match.group(1).upper()
                    
                    # Zmapuj kod na czytelnÄ… nazwÄ™
                    size_names = {
                        'O': 'Original',
                        '5K': 'X-Large 5K',
                        '4K': 'X-Large 4K', 
                        '3K': 'X-Large 3K',
                        'K': 'Large 2048',
                        'H': 'Large 1600',
                        'L': 'Large 1024',
                        'C': 'Medium 800',
                        'Z': 'Medium 640',
                        'B': 'Large 1024'
                    }
                    best_size_name = size_names.get(best_size_name, best_size_name)
            except:
                pass
            
            # PRIORYTET 2: JeÅ›li nie ma obrazka, sprawdÅº link Original w menu Sizes
            if not best_url:
                try:
                    # Link do oryginaÅ‚u: <a href="/photos/.../sizes/o/">Original</a>
                    original_link = self.driver.find_element(By.CSS_SELECTOR, "a[href*='/sizes/o/']")
                    # PrzejdÅº do strony z oryginaÅ‚em
                    original_url = original_link.get_attribute('href')
                    self.driver.get(original_url)
                    time.sleep(1)
                    
                    img = self.driver.find_element(By.CSS_SELECTOR, "#allsizes-photo img")
                    best_url = img.get_attribute('src')
                    best_size_name = "Original"
                except:
                    pass
            
            # Zamknij kartÄ™ i wrÃ³Ä‡ do gÅ‚Ã³wnej
            self.driver.close()
            self.driver.switch_to.window(self.driver.window_handles[0])
            
            return best_url, best_size_name
            
        except Exception as e:
            # W razie bÅ‚Ä™du, zamknij dodatkowe karty i wrÃ³Ä‡ do gÅ‚Ã³wnej
            try:
                while len(self.driver.window_handles) > 1:
                    self.driver.close()
                    self.driver.switch_to.window(self.driver.window_handles[0])
            except:
                pass
            return None, None
    
    def extract_photo_urls_from_page(self):
        """WyciÄ…gnij wszystkie URL-e zdjÄ™Ä‡ z bieÅ¼Ä…cej strony wraz z nazwami"""
        # ZnajdÅº wszystkie karty zdjÄ™Ä‡
        photo_cards = self.driver.find_elements(By.CSS_SELECTOR, ".photo-card")
        
        # Licznik dodanych na tej stronie
        added_count = 0
        
        for idx, card in enumerate(photo_cards, 1):
            try:
                # ZnajdÅº link z tytuÅ‚em
                title_link = card.find_element(By.CSS_SELECTOR, "a.photo-link")
                title = title_link.get_attribute('title')
                photo_page_url = title_link.get_attribute('href')
                
                if photo_page_url and title:
                    # WyodrÄ™bnij ID zdjÄ™cia z URL (np. /photos/user/123456789/ -> 123456789)
                    photo_id_match = re.search(r'/photos/[^/]+/(\d+)', photo_page_url)
                    photo_id = photo_id_match.group(1) if photo_id_match else str(idx)
                    
                    # WyczyÅ›Ä‡ nazwÄ™ pliku (usuÅ„ niedozwolone znaki)
                    safe_title = re.sub(r'[<>:"/\\|?*]', '_', title)
                    # Dodaj ID zdjÄ™cia do nazwy pliku dla unikalnoÅ›ci
                    filename = f"{safe_title}_{photo_id}.jpg"
                    
                    # PRIORYTET 1: SprawdÅº czy plik juÅ¼ istnieje
                    if self._is_already_downloaded(filename):
                        with self.download_lock:
                            self.download_stats["skipped_scan"] += 1
                            # Aktualizuj progressbar dla pominiÄ™tych
                            if self.download_pbar:
                                self.download_pbar.update(1)
                                self.download_pbar.set_postfix_str(f"âŠ˜ juÅ¼: {filename[:30]}...")
                        continue
                    
                    # PRIORYTET 2: SprawdÅº czy URL jest juÅ¼ znany z pliku
                    if filename in self.known_urls:
                        url, saved_title, size = self.known_urls[filename]
                        
                        with self.download_lock:
                            self.download_stats["from_cache"] += 1
                            self.global_index += 1
                            current_index = self.global_index
                        
                        # NATYCHMIAST dodaj do kolejki pobierania
                        self.download_queue.put((url, filename, current_index, 0))
                        added_count += 1
                        continue
                    
                    # PRIORYTET 3: Pobierz URL ze strony (tylko jeÅ›li nie mamy go w pliku)
                    high_res_url, size_name = self.get_highest_resolution_url(photo_page_url)
                    
                    if high_res_url:
                        # NAPRAW: usuÅ„ podwÃ³jne https:
                        if high_res_url.startswith('https:https://'):
                            high_res_url = high_res_url.replace('https:https://', 'https://')
                        elif not high_res_url.startswith('https://'):
                            high_res_url = 'https://' + high_res_url.lstrip('/')
                        
                        # SprawdÅº czy to nowe zdjÄ™cie (URL)
                        if high_res_url not in self.photo_urls:
                            self.photo_urls.add(high_res_url)
                            
                            # NATYCHMIAST zapisz URL do pliku
                            self._save_single_url(high_res_url, filename, title, size_name or 'unknown')
                            
                            # NATYCHMIAST dodaj do kolejki pobierania
                            with self.download_lock:
                                self.global_index += 1
                                current_index = self.global_index
                            
                            self.download_queue.put((high_res_url, filename, current_index, 0))
                            added_count += 1
                        
            except Exception as e:
                continue
        
        return added_count
    
    def _save_single_url(self, url, filename, title, size):
        """Zapisz pojedynczy URL do pliku natychmiast po znalezieniu"""
        os.makedirs(self.download_folder, exist_ok=True)
        with open(self.urls_file, 'a', encoding='utf-8') as f:
            f.write(f"{filename}\t{url}\t{title}\t{size}\n")
    
    def save_urls_to_file(self, urls):
        """Zapisz URL-e do pliku"""
        # Upewnij siÄ™, Å¼e folder istnieje
        os.makedirs(self.download_folder, exist_ok=True)
        
        with open(self.urls_file, 'a', encoding='utf-8') as f:
            for item in urls:
                size_info = item.get('size', 'unknown')
                f.write(f"{item['filename']}\t{item['url']}\t{item['title']}\t{size_info}\n")
    
    def _handle_rate_limit(self):
        """ObsÅ‚uga rate limit - pauza na 30 minut"""
        print("\nğŸš« Wykryto rate limit (HTTP 429)")
        print("â¸ï¸  Pauzowanie pobierania na 30 minut...")
        
        # Zatrzymaj wszystkie wÄ…tki
        self.rate_limit_event.clear()
        
        # Pauza 30 minut
        import time
        pause_minutes = 60
        for minute in range(pause_minutes, 0, -1):
            print(f"â° PozostaÅ‚o {minute} minut...", end='\r')
            time.sleep(60)
        
        print("â–¶ï¸  Wznawianie pobierania...")
        
        # Wznow wszystkie wÄ…tki
        self.rate_limit_event.set()
    
    def download_worker(self):
        """WÄ…tek pobierajÄ…cy zdjÄ™cia z kolejki"""
        while True:
            item = self.download_queue.get()
            if item is None:  # SygnaÅ‚ zakoÅ„czenia
                break
            
            url, filename, index, total = item
            
            # SprawdÅº czy plik juÅ¼ istnieje
            if self._is_already_downloaded(filename):
                with self.download_lock:
                    self.download_stats["skipped"] += 1
                    if self.download_pbar:
                        self.download_pbar.update(1)
                        self.download_pbar.set_postfix_str(f"âŠ˜ {filename[:40]}...")
                self.download_queue.task_done()
                continue
            
            # SprawdÅº czy to wczeÅ›niej nieudane pobranie
            was_failed = filename in self.failed_files
            
            try:
                # Czekaj na wznowienie jeÅ›li jest rate limit
                self.rate_limit_event.wait()
                
                response = requests.get(url, timeout=30)
                if response.status_code == 200:
                    filepath = os.path.join(self.download_folder, filename)
                    with open(filepath, 'wb') as f:
                        f.write(response.content)
                    
                    # SprawdÅº czy plik nie jest zbyt maÅ‚y (prawdopodobnie bÅ‚Ä…d)
                    if os.path.getsize(filepath) < 1024:
                        os.remove(filepath)
                        raise Exception("Pobrany plik jest zbyt maÅ‚y (< 1KB)")
                    
                    # Dodaj do listy pobranych
                    self.downloaded_files.add(filename)
                    
                    # UsuÅ„ z listy nieudanych (jeÅ›li byÅ‚o)
                    if was_failed:
                        self.failed_files.discard(filename)
                    
                    with self.download_lock:
                        self.download_stats["successful"] += 1
                        if was_failed:
                            self.download_stats["resumed"] += 1
                        if self.download_pbar:
                            self.download_pbar.update(1)
                            self.download_pbar.set_postfix_str(f"âœ“ {filename[:40]}...")
                else:
                    raise Exception(f"HTTP {response.status_code}")
                            
            except Exception as e:
                error_msg = str(e)[:100]
                
                # Specjalna obsÅ‚uga rate limit (HTTP 429)
                if "HTTP 429" in error_msg:
                    with self.download_lock:
                        if self.download_pbar:
                            self.download_pbar.set_postfix_str(f"ğŸš« Rate limit! Pauza...")
                        # Wstrzymaj wszystkie wÄ…tki na 30 minut
                        self._handle_rate_limit()
                        # Po pauzie dodaj zdjÄ™cie z powrotem do kolejki
                        self.download_queue.put((url, filename, index, total))
                        self.download_queue.task_done()
                        continue
                
                # Zapisz do listy nieudanych
                if filename not in self.failed_files:
                    self._save_failed_download(filename, url, error_msg)
                    self.failed_files.add(filename)
                
                with self.download_lock:
                    self.download_stats["failed"] += 1
                    if self.download_pbar:
                        self.download_pbar.update(1)
                        self.download_pbar.set_postfix_str(f"âœ— {filename[:40]}...")
            
            finally:
                self.download_queue.task_done()
    
    def process_all_pages(self):
        """PrzejdÅº przez wszystkie strony albumu i zbierz URL-e zdjÄ™Ä‡"""
        print("Wykrywanie liczby stron...")
        
        # ZaÅ‚aduj pierwszÄ… stronÄ™
        self.driver.get(self.album_url)
        
        # Poczekaj na zaÅ‚adowanie
        WebDriverWait(self.driver, 10).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "img[src*='staticflickr.com']"))
        )
        
        # Pobierz caÅ‚kowitÄ… liczbÄ™ zdjÄ™Ä‡ w albumie
        self.total_photos = self.get_total_photos_count()
        if self.total_photos > 0:
            print(f"ğŸ“Š Wykryto {self.total_photos} zdjÄ™Ä‡ w albumie")
        
        # Wykryj caÅ‚kowitÄ… liczbÄ™ stron
        total_pages = self.get_total_pages()
        print(f"âœ“ Wykryto {total_pages} stron")
        
        # UtwÃ³rz progressbar dla pobierania
        print()  # Nowa linia przed progressbarem
        self.download_pbar = tqdm(
            total=self.total_photos if self.total_photos > 0 else None,
            desc="ğŸ“¥ Pobieranie",
            unit=" zdjÄ™Ä‡",
            bar_format="{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]",
            position=0,
            leave=True
        )
        
        # Uruchom wÄ…tki pobierajÄ…ce (4 wÄ…tki rÃ³wnolegle)
        num_workers = 4
        download_threads = []
        for _ in range(num_workers):
            t = threading.Thread(target=self.download_worker, daemon=True)
            t.start()
            download_threads.append(t)
        
        # PrzetwÃ³rz kaÅ¼dÄ… stronÄ™ (bez printÃ³w - tylko progressbar)
        for page_num in range(1, total_pages + 1):
            # PrzejdÅº na odpowiedniÄ… stronÄ™
            if page_num == 1:
                page_url = self.album_url
            else:
                page_url = f"{self.album_url}/page{page_num}"
            
            self.driver.get(page_url)
            
            # Poczekaj na zaÅ‚adowanie zdjÄ™Ä‡
            try:
                WebDriverWait(self.driver, 10).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, "img[src*='staticflickr.com']"))
                )
            except:
                continue
            
            # PrzewiÅ„ aby zaÅ‚adowaÄ‡ wszystkie zdjÄ™cia na tej stronie
            self.scroll_to_load_all_on_page()
            
            # WyciÄ…gnij URL-e z tej strony i NATYCHMIAST dodaj do kolejki pobierania
            self.extract_photo_urls_from_page()
            
            # KrÃ³tka pauza miÄ™dzy stronami
            time.sleep(0.5)
        
        # Poczekaj na zakoÅ„czenie wszystkich pobieraÅ„
        self.download_queue.join()
        
        # Zamknij progressbar
        if self.download_pbar:
            self.download_pbar.close()
        
        # Zatrzymaj wÄ…tki
        for _ in range(num_workers):
            self.download_queue.put(None)
        for t in download_threads:
            t.join()
        
        return list(self.photo_urls)
    
    def download_photo(self, url, filename):
        """Pobierz pojedyncze zdjÄ™cie"""
        try:
            response = requests.get(url, timeout=30)
            if response.status_code == 200:
                filepath = os.path.join(self.download_folder, filename)
                with open(filepath, 'wb') as f:
                    f.write(response.content)
                return True
            else:
                # SprÃ³buj alternatywnych rozmiarÃ³w jeÅ›li _b nie dziaÅ‚a
                if '_b.jpg' in url:
                    alt_url = url.replace('_b.jpg', '_c.jpg')  # 800px
                    response = requests.get(alt_url, timeout=30)
                    if response.status_code == 200:
                        filepath = os.path.join(self.download_folder, filename)
                        with open(filepath, 'wb') as f:
                            f.write(response.content)
                        return True
                
                print(f"  âœ— BÅ‚Ä…d {response.status_code}")
                return False
        except Exception as e:
            print(f"  âœ— BÅ‚Ä…d: {str(e)[:50]}")
            return False
    
    def run(self):
        """GÅ‚Ã³wna funkcja uruchamiajÄ…ca caÅ‚y proces"""
        try:
            print(f"\n{'='*50}")
            print(f"FLICKR ALBUM DOWNLOADER")
            print(f"{'='*50}")
            print(f"Album: {self.album_url}")
            print(f"Folder: {self.download_folder}\n")
            
            # PokaÅ¼ status wznowienia
            if self.downloaded_files:
                print(f"ğŸ“‚ Tryb wznowienia: pominiÄ™to {len(self.downloaded_files)} juÅ¼ pobranych plikÃ³w")
            if self.failed_files:
                print(f"â†» Ponowne pobieranie: {len(self.failed_files)} wczeÅ›niej nieudanych plikÃ³w\n")
            
            self.setup_driver()
            print("âœ“ PrzeglÄ…darka uruchomiona\n")
            
            # PrzetwÃ³rz wszystkie strony i zbierz URL-e (rÃ³wnoczeÅ›nie pobierajÄ…c)
            photo_urls = self.process_all_pages()
            
            if not photo_urls:
                print("âœ— Nie znaleziono Å¼adnych zdjÄ™Ä‡!")
                return
            
            # Podsumowanie
            print(f"\n{'='*50}")
            print(f"POBIERANIE ZAKOÅƒCZONE!")
            print(f"{'='*50}")
            
            # PokaÅ¼ statystyki skanowania i cache
            if self.download_stats['skipped_scan'] > 0:
                print(f"âŠ˜ PominiÄ™to podczas skanowania: {self.download_stats['skipped_scan']} (juÅ¼ pobrane)")
            if self.download_stats['from_cache'] > 0:
                print(f"ğŸ“‹ URL-e pobrane z cache: {self.download_stats['from_cache']} (plik photo_urls.txt)")
            
            # PokaÅ¼ statystyki pobierania
            print(f"âœ“ Pobrano pomyÅ›lnie: {self.download_stats['successful']}")
            if self.download_stats['resumed'] > 0:
                print(f"â†» Wznowiono (wczeÅ›niej nieudane): {self.download_stats['resumed']}")
            if self.download_stats['skipped'] > 0:
                print(f"âŠ˜ PominiÄ™to podczas pobierania: {self.download_stats['skipped']}")
            if self.download_stats['failed'] > 0:
                print(f"âœ— BÅ‚Ä™dy: {self.download_stats['failed']}")
                print(f"  Lista nieudanych: {os.path.abspath(self.failed_file)}")
            
            print(f"\nğŸ“Š Razem zdjÄ™Ä‡ w albumie: {len(self.photo_urls) + self.download_stats['skipped_scan']}")
            print(f"ğŸ“ Lokalizacja: {os.path.abspath(self.download_folder)}")
            print(f"ğŸ“„ Plik z URL-ami: {os.path.abspath(self.urls_file)}")
            print(f"{'='*50}")
            
            if self.download_stats['failed'] > 0:
                print(f"\nğŸ’¡ Uruchom program ponownie, aby sprÃ³bowaÄ‡ pobraÄ‡ nieudane pliki.")
            print()
            
        except Exception as e:
            print(f"\nâœ— WystÄ…piÅ‚ bÅ‚Ä…d: {str(e)}")
            import traceback
            traceback.print_exc()
        
        finally:
            if self.driver:
                self.driver.quit()
                print("\nâœ“ PrzeglÄ…darka zamkniÄ™ta")


if __name__ == "__main__":
    # Wklej tutaj URL albumu Flickr (bez /page1 na koÅ„cu)
    ALBUM_URL = "https://www.flickr.com/photos/ikmgdansk/albums/72177720330390070/"
    
    # MoÅ¼esz zmieniÄ‡ folder docelowy
    DOWNLOAD_FOLDER = "MusicJam"

    downloader = FlickrAlbumDownloader(ALBUM_URL, DOWNLOAD_FOLDER)
    downloader.run()